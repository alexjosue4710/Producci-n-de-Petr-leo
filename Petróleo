import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# ----------------------------------------------------------------------
# 1. CARGA DE INFORMACI√ìN Y LIMPIEZA INICIAL
# ----------------------------------------------------------------------

try:
    df = pd.read_excel('alberta.xlsx')
except FileNotFoundError:
    print("Error: El archivo 'alberta.xlsx' no se encontr√≥. ¬°Verifique la ruta!")
    raise

df['Date'] = pd.to_datetime(df['Date'])

# Establecer 'Date' como √≠ndice
data_ts = df[['Date', 'Oil (BBL)']].copy().set_index('Date').sort_index()

# Limpieza: Remover meses con producci√≥n cero o nula
data_ts_clean = data_ts[data_ts['Oil (BBL)'] > 0].copy()

print("Datos cargados. Total de registros limpios:", len(data_ts_clean))

# ----------------------------------------------------------------------
# 2. VISUALIZACI√ìN DE LA SERIE DE TIEMPO COMPLETA
# ----------------------------------------------------------------------

plt.figure(figsize=(14, 6))
plt.plot(data_ts_clean.index, data_ts_clean['Oil (BBL)'], 
         label='Producci√≥n de Petr√≥leo (BBL/mes)', color='green', linewidth=1.5)
plt.fill_between(data_ts_clean.index, data_ts_clean['Oil (BBL)'], color='green', alpha=0.2)
plt.title('Producci√≥n de Petr√≥leo vs. Tiempo ')
plt.xlabel('Fecha')
plt.ylabel('Petr√≥leo (BBL/mes)')
plt.legend()
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.show()

# ----------------------------------------------------------------------
# 3. IDENTIFICACI√ìN Y VISUALIZACI√ìN DE OUTLIERS (BOXPLOT)
# ----------------------------------------------------------------------

# Se utiliza un Boxplot para visualizar la distribuci√≥n y los valores at√≠picos
# La media es arrastrada por el pico, lo que hace que casi todos los puntos parezcan outliers.
plt.figure(figsize=(8, 6))
plt.boxplot(data_ts_clean['Oil (BBL)'].values, vert=False, patch_artist=True, 
            boxprops=dict(facecolor='lightblue'))
plt.title('Identificaci√≥n de Outliers (Pico de Producci√≥n)')
plt.xlabel('Petr√≥leo (BBL/mes)')
plt.yticks([1], ['Producci√≥n'])
plt.grid(True, which='major', linestyle='--', linewidth=0.5)
plt.show()

############################################# ARPS ############################################
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import r2_score, mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D
from tensorflow.keras.callbacks import EarlyStopping

# --- Funciones Esenciales ---
def arps_hyperbolic(t, qi, Di, b):
    if b < 1e-6:
        return qi * np.exp(-Di * t)
    return qi / (1 + b * Di * t)**(1/b)

def mape(y_true, y_pred):
    epsilon = 1e-10 
    return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100

# ----------------------------------------------------------------------
# 4.1. PREPARACI√ìN DE DATOS Y AJUSTE BASE DE ARPS
# ----------------------------------------------------------------------
# (Re-carga y pre-procesamiento para asegurar que todas las variables existan)
df = pd.read_excel('alberta.xlsx')
df['Date'] = pd.to_datetime(df['Date'])
data_ts = df[['Date', 'Oil (BBL)']].copy().set_index('Date').sort_index()
data_ts_clean = data_ts[data_ts['Oil (BBL)'] > 0].copy()
data_stable_decline = data_ts_clean.iloc[50:].copy() # Segmentaci√≥n de la fase estable
production_data_original = data_stable_decline['Oil (BBL)'].values
N_total = len(production_data_original)
train_len = int(N_total * 0.8) 
t_total = np.arange(N_total)
y_train = production_data_original[:train_len]
y_test = production_data_original[train_len:]
t_test = t_total[train_len:]
initial_qi = y_train[0]
popt, pcov = curve_fit(arps_hyperbolic, t_train, y_train, p0=[initial_qi, 0.1, 0.5], bounds=([initial_qi * 0.5, 0.001, 0.0], [initial_qi * 1.5, 2.0, 0.99]))
qi_opt, Di_opt, b_opt = popt
# Pron√≥stico de Arps Puro (Baseline)
arps_forecast_test = arps_hyperbolic(t_test, qi_opt, Di_opt, b_opt)
arps_history_forecast = arps_hyperbolic(t_total, qi_opt, Di_opt, b_opt)

########################## TRATAMIENTO DE LOS RESIDUALES DEL PRONOSTICO DE ARPS ###############################
residual_values = (production_data_original - arps_history_forecast).reshape(-1, 1)
scaler_res = MinMaxScaler(feature_range=(0, 1))
scaled_residual_data = scaler_res.fit_transform(residual_values)
train_data_scaled_res = scaled_residual_data[:train_len]
SEQ_LENGTH = 12 

# Definici√≥n de Secuencias para Redes Neuronales
def create_sequences_single_step(data, seq_length, is_dense=False):
    X, y = [], []
    for i in range(len(data) - seq_length - 1):
        if is_dense:
             X.append(data[i:(i + seq_length)].flatten())
        else:
             X.append(data[i:(i + seq_length)])
        y.append(data[i + seq_length, 0])
    return np.array(X), np.array(y)

# Funci√≥n Auxiliar para Pron√≥stico Iterativo
def iterative_forecast(model, X_initial, scaler, arps_forecast, seq_length, is_dense=False):
    forecast_steps = len(arps_forecast)
    predicted_residual_scaled = []
    current_batch = X_initial.copy()

    for i in range(forecast_steps):
        prediction = model.predict(current_batch, verbose=0)
        current_prediction = prediction[0, 0] if not is_dense else prediction[0]
        predicted_residual_scaled.append(current_prediction)
        if is_dense:
            new_input = np.delete(current_batch[0], 0) 
            current_batch = np.append(new_input, current_prediction).reshape(1, seq_length)
        else:
            new_input = np.delete(current_batch[0], 0, axis=0) 
            current_batch = np.append(new_input, [[current_prediction]]).reshape(1, seq_length, 1)

    predicted_residual = scaler.inverse_transform(np.array(predicted_residual_scaled).reshape(-1, 1))
    return arps_forecast.reshape(-1, 1) + predicted_residual

# Variables globales para la tabla final
global y_test_final, test_index_dates_final, arps_forecast_pure, history_lstm, history_dense, history_cnn_lstm
y_test_final = y_test.flatten()
test_index_dates_final = data_stable_decline.index[train_len:][:len(y_test)]
arps_forecast_pure = arps_forecast_test.flatten()

# --- Definici√≥n del Early Stopping ( control de sobreajuste) ---
early_stop = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)


# ----------------------------------------------------------------------
# 4.2. MODELO H√çBRIDO: LSTM SIMPLE (Guarda en history_lstm)
# ----------------------------------------------------------------------
X_train_lstm, y_train_lstm = create_sequences_single_step(train_data_scaled_res, SEQ_LENGTH)
X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)
X_initial_lstm = train_data_scaled_res[-SEQ_LENGTH:].reshape(1, SEQ_LENGTH, 1)

model_lstm = Sequential([
    LSTM(100, return_sequences=False, input_shape=(SEQ_LENGTH, 1)), 
    Dropout(0.2),
    Dense(1)
])
model_lstm.compile(optimizer='adam', loss='mean_squared_error')
history_lstm = model_lstm.fit(X_train_lstm, y_train_lstm, epochs=300, batch_size=16, validation_split=0.1, verbose=0) 
global hybrid_forecast_LSTM
hybrid_forecast_LSTM = iterative_forecast(model_lstm, X_initial_lstm, scaler_res, arps_forecast_test, SEQ_LENGTH).flatten()

print("LSTM Simple - **OK**")

# ----------------------------------------------------------------------
# 4.3. MODELO H√çBRIDO: RED DENSA (Guarda en history_dense)
# ----------------------------------------------------------------------
X_train_dense, y_train_dense = create_sequences_single_step(train_data_scaled_res, SEQ_LENGTH, is_dense=True)
X_initial_dense = train_data_scaled_res[-SEQ_LENGTH:].flatten().reshape(1, SEQ_LENGTH)

model_dense = Sequential([
    Dense(100, activation='relu', input_shape=(SEQ_LENGTH,)), 
    Dropout(0.2),
    Dense(50, activation='relu'),
    Dropout(0.2),
    Dense(1)
])
model_dense.compile(optimizer='adam', loss='mean_squared_error')
history_dense = model_dense.fit(X_train_dense, y_train_dense, epochs=300, batch_size=16, validation_split=0.1, verbose=0)
global hybrid_forecast_Dense
hybrid_forecast_Dense = iterative_forecast(model_dense, X_initial_dense, scaler_res, arps_forecast_test, SEQ_LENGTH, is_dense=True).flatten()

print("Red Densa - **OK**")

# ----------------------------------------------------------------------
# 4.4. MODELO H√çBRIDO: CNN-LSTM (Guarda en history_cnn_lstm)
# ----------------------------------------------------------------------
X_train_cnn_lstm, y_train_cnn_lstm = create_sequences_single_step(train_data_scaled_res, SEQ_LENGTH)
X_train_cnn_lstm = X_train_cnn_lstm.reshape(X_train_cnn_lstm.shape[0], X_train_cnn_lstm.shape[1], 1)
X_initial_cnn_lstm = train_data_scaled_res[-SEQ_LENGTH:].reshape(1, SEQ_LENGTH, 1)

model_cnn_lstm = Sequential([
    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(SEQ_LENGTH, 1)),
    Dropout(0.2),
    LSTM(50, return_sequences=False),
    Dropout(0.2),
    Dense(1)
])
model_cnn_lstm.compile(optimizer='adam', loss='mean_squared_error')
history_cnn_lstm = model_cnn_lstm.fit(X_train_cnn_lstm, y_train_cnn_lstm, epochs=100, batch_size=16, validation_split=0.1, verbose=0)
global hybrid_forecast_CNN_LSTM
hybrid_forecast_CNN_LSTM = iterative_forecast(model_cnn_lstm, X_initial_cnn_lstm, scaler_res, arps_forecast_test, SEQ_LENGTH).flatten()

print("CNN-LSTM - **OK**")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score, mean_squared_error
# (Asume que todas las variables globales y de pron√≥stico est√°n cargadas)

# --- Funciones Esenciales ---
def mape(y_true, y_pred):
    epsilon = 1e-10 
    return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100

# ----------------------------------------------------------------------
# 5.1. GR√ÅFICAS DE P√âRDIDA (LOSS) PARA DIAGN√ìSTICO DE AJUSTE
# ----------------------------------------------------------------------

def plot_loss(history, title):
    plt.figure(figsize=(8, 5))
    plt.plot(history.history['loss'], label='P√©rdida de Entrenamiento', color='blue')
    plt.plot(history.history['val_loss'], label='P√©rdida de Validaci√≥n', color='red')
    plt.title(f'Diagn√≥stico de Ajuste: {title}')
    plt.xlabel('√âpoca')
    plt.ylabel('P√©rdida (MSE)')
    plt.legend()
    plt.grid(True)
    plt.show()

# Ejecutar las gr√°ficas
plot_loss(history_lstm, "LSTM Simple")
plot_loss(history_dense, "Red Densa")
plot_loss(history_cnn_lstm, "CNN-LSTM")


# ----------------------------------------------------------------------
# 5.2. TABLAS Y GR√ÅFICO CONSOLIDADO (Igual que en el script anterior)
# ----------------------------------------------------------------------

# DataFrame de Valores
final_df = pd.DataFrame({
    'Fecha': test_index_dates_final,
    'Producci√≥n Real': y_test_final,
    'Pron√≥stico Arps Puro': arps_forecast_pure,
    'Pron√≥stico LSTM': hybrid_forecast_LSTM,
    'Pron√≥stico Red Densa': hybrid_forecast_Dense,
    'Pron√≥stico CNN-LSTM': hybrid_forecast_CNN_LSTM
})
final_df = final_df.set_index('Fecha')
final_df = final_df.round(2)

# DataFrame de M√©tricas
def calculate_metrics(y_true, y_pred):
    return {
        'R2': r2_score(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAPE': mape(y_true, y_pred)
    }

metrics = {
    'Arps Puro': calculate_metrics(y_test_final, final_df['Pron√≥stico Arps Puro'].values),
    'H√≠brido LSTM': calculate_metrics(y_test_final, final_df['Pron√≥stico LSTM'].values),
    'H√≠brido Red Densa': calculate_metrics(y_test_final, final_df['Pron√≥stico Red Densa'].values),
    'H√≠brido CNN-LSTM': calculate_metrics(y_test_final, final_df['Pron√≥stico CNN-LSTM'].values),
}

metrics_df = pd.DataFrame(metrics).T
metrics_df['RMSE'] = metrics_df['RMSE'].round(2)
metrics_df['MAPE'] = metrics_df['MAPE'].round(2)
metrics_df['R2'] = metrics_df['R2'].round(4)
metrics_df.columns = ['R2', 'RMSE (BBL/mes)', 'MAPE (%)']

print("\n----------------------------------------------------------")
print("‚≠ê **Tabla de M√©tricas de Rendimiento Final**")
print("----------------------------------------------------------")
print(metrics_df.to_markdown(floatfmt=".4f"))

print("\n----------------------------------------------------------")
print("üìä **Tabla Comparativa de Pron√≥sticos (Valores BBL/mes)**")
print("----------------------------------------------------------")
print(final_df.to_markdown(floatfmt=".2f"))

# Gr√°fico Consolidado
plt.figure(figsize=(16, 8))
plt.plot(final_df.index, final_df['Producci√≥n Real'], 
         label='1. Producci√≥n Real (Test)', color='blue', linewidth=3)
plt.plot(final_df.index, final_df['Pron√≥stico Arps Puro'], 
         label='2. Pron√≥stico Arps Puro (Baseline)', color='orange', linestyle=':', linewidth=2)
plt.plot(final_df.index, final_df['Pron√≥stico LSTM'], 
         label='3. H√≠brido LSTM', color='green', linestyle='--', linewidth=2)
plt.plot(final_df.index, final_df['Pron√≥stico Red Densa'], 
         label='4. H√≠brido Red Densa', color='darkcyan', linestyle='-.', linewidth=2)
plt.plot(final_df.index, final_df['Pron√≥stico CNN-LSTM'], 
         label='5. H√≠brido CNN-LSTM', color='red', linestyle='-', linewidth=1.5)

plt.title('Comparaci√≥n Final de Modelos de Declinaci√≥n vs. Producci√≥n Real')
plt.xlabel('Fecha')
plt.ylabel('Petr√≥leo (BBL/mes)')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


# ----------------------------------------------------------------------
# 5.3. PAR√ÅMETROS DE CADA MODELO (PESOS Y SESGOS)
# ----------------------------------------------------------------------

def print_model_params(model, name):
    print(f"\n--- Par√°metros del Modelo: {name} ---")
    weights = model.get_weights()
    for i, w in enumerate(weights):
        print(f"  Capa {i+1} - Peso/Sesgo: {w.shape}")
        print(f"  > Norma L2 del tensor: {np.linalg.norm(w):.4f}")
        if w.ndim > 1:
            print(f"  > Primeros 5 valores (Pesos): {w.flatten()[:5]}")
        else:
             print(f"  > Primeros 5 valores (Sesgos): {w.flatten()[:5]}")

print_model_params(model_lstm, "H√≠brido LSTM Simple")
print_model_params(model_dense, "H√≠brido Red Densa")
print_model_params(model_cnn_lstm, "H√≠brido CNN-LSTM")

# ----------------------------------------------------------------------
# 6.1. ARQUITECTURA DE LAS REDES NEURONALES
# ----------------------------------------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# Aseg√∫rese de que las variables model_lstm, model_dense, y model_cnn_lstm est√©n definidas
# Ejecute este c√≥digo DESPU√âS del script de Modelado (Punto 4)

def print_model_summary(model, name):
    """
    Imprime un encabezado y luego el resumen de la arquitectura del modelo
    utilizando model.summary() de Keras.
    """
    print("\n" + "="*80)
    print(f"--- RESUMEN DE ARQUITECTURA: {name} ---")
    print("="*80)
    model.summary()
    print("\n")


# 1. Resumen de la Red LSTM Simple
print_model_summary(model_lstm, "H√≠brido LSTM Simple")

# 2. Resumen de la Red Densa
print_model_summary(model_dense, "H√≠brido Red Densa (Fully Connected)")

# 3. Resumen de la Red CNN-LSTM
print_model_summary(model_cnn_lstm, "H√≠brido CNN-LSTM (Convolucional)")

# ----------------------------------------------------------------------
# 7.1. VISUALIZACI√ìN DE LA DIVISI√ìN DEL SET DE DATOS
# ----------------------------------------------------------------------
# 1. Segmentaci√≥n de la fase estable (Remoci√≥n de outliers iniciales)
data_stable_decline = data_ts_clean.iloc[50:].copy() 
production_data_original = data_stable_decline['Oil (BBL)'].values

# 2. Definici√≥n de la Divisi√≥n 80/20
N_total = len(production_data_original)
train_len = int(N_total * 0.8) # 80% para entrenamiento

# 3. Separaci√≥n de los conjuntos (Indices y Valores)
train_data_indices = data_stable_decline.index[:train_len]
test_data_indices = data_stable_decline.index[train_len:]

train_data_values = production_data_original[:train_len]
test_data_values = production_data_original[train_len:]

# 4. Generaci√≥n de la Gr√°fica
plt.figure(figsize=(16, 6))
plt.plot(train_data_indices, train_data_values, 
         label=f'Conjunto de Entrenamiento (Train: {train_len} meses)', 
         color='blue', linewidth=2)
plt.plot(test_data_indices, test_data_values, 
         label=f'Conjunto de Prueba (Test: {N_total - train_len} meses)', 
         color='red', linewidth=2)

# A√±adir una l√≠nea vertical para indicar el punto de divisi√≥n
plt.axvline(x=test_data_indices[0], color='black', linestyle='--', linewidth=1, 
            label='Punto de Divisi√≥n (Fin de Entrenamiento)')

plt.title('Divisi√≥n de la Serie de Tiempo Estable (Train vs. Test)')
plt.xlabel('Fecha')
plt.ylabel('Petr√≥leo (BBL/mes)')
plt.legend()
plt.grid(True, linestyle=':', alpha=0.7)
plt.show()

# ----------------------------------------------------------------------
# 8.1. VISUALIZACI√ìN SET DE DATOS VS ARPS
# ----------------------------------------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# --- Asumiendo que las variables de Arps y los datos est√°n cargados ---
# (Definidas en el script de modelado, Punto 4)
# data_stable_decline, production_data_original, t_total, qi_opt, Di_opt, b_opt

def arps_hyperbolic(t, qi, Di, b):
    # Ecuaci√≥n de declinaci√≥n hiperb√≥lica de Arps
    if b < 1e-6:
        return qi * np.exp(-Di * t)
    return qi / (1 + b * Di * t)**(1/b)

# 1. Generar la Curva de Arps para el periodo completo (Train + Test)
arps_curve_full = arps_hyperbolic(t_total, qi_opt, Di_opt, b_opt)

# 2. Generaci√≥n de la Gr√°fica
plt.figure(figsize=(16, 6))

# A. Producci√≥n Real (Datos Estables Segmentados)
plt.plot(data_stable_decline.index, production_data_original, 
         label='Producci√≥n Real (Datos Estables)', 
         color='blue', linewidth=2)

# B. Curva de Ajuste de Arps (Modelo Te√≥rico)
plt.plot(data_stable_decline.index, arps_curve_full, 
         label=f'Ajuste de Arps: qi={qi_opt:.2f}, Di={Di_opt:.4f}, b={b_opt:.4f}', 
         color='orange', linestyle='--', linewidth=3)

plt.title('Ajuste del Modelo de Declinaci√≥n de Arps vs. Producci√≥n Real (Fase Estable)')
plt.xlabel('Fecha')
plt.ylabel('Petr√≥leo (BBL/mes)')
plt.legend()
plt.grid(True, linestyle=':', alpha=0.7)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# Aseg√∫rese de que las variables globales ya est√©n definidas por el script de modelado (Punto 4)
# Variables requeridas: y_test_final, test_index_dates_final, arps_forecast_pure

# 1. Generaci√≥n de la Gr√°fica de Comparaci√≥n de la Zona de Prueba
plt.figure(figsize=(12, 6))

# A. Producci√≥n Real (Conjunto de Prueba)
plt.plot(test_index_dates_final, y_test_final, 
         label='Producci√≥n Real (Test Set)', 
         color='blue', linewidth=2.5)

# B. Pron√≥stico Base (Arps Puro)
plt.plot(test_index_dates_final, arps_forecast_pure, 
         label='Pron√≥stico Arps Puro (Baseline)', 
         color='orange', linestyle=':', linewidth=3)

plt.title('Comparaci√≥n: Producci√≥n Real vs. Pron√≥stico Arps Puro (Conjunto de Prueba)')
plt.xlabel('Fecha')
plt.ylabel('Petr√≥leo (BBL/mes)')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# ----------------------------------------------------------------------
# 9.1. VISUALIZACI√ìN DE LOS ACUMULADOS DE PRODICCI√ìN
# ----------------------------------------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# --- Asumiendo que las variables globales de pron√≥stico est√°n cargadas ---
# Variables requeridas: 
# y_test_final, test_index_dates_final, 
# hybrid_forecast_LSTM, hybrid_forecast_Dense, hybrid_forecast_CNN_LSTM, arps_forecast_pure

# 1. Crear DataFrame con las series de tiempo del conjunto de prueba
test_forecast_df = pd.DataFrame({
    'Fecha': test_index_dates_final,
    'Producci√≥n Real': y_test_final,
    'Pron√≥stico Arps Puro': arps_forecast_pure,
    'Pron√≥stico LSTM': hybrid_forecast_LSTM,
    'Pron√≥stico Red Densa': hybrid_forecast_Dense,
    'Pron√≥stico CNN-LSTM': hybrid_forecast_CNN_LSTM
}).set_index('Fecha')

# 2. Calcular la Producci√≥n Acumulada (Cumulative Sum) para cada columna
cumulative_production_df = test_forecast_df.cumsum()

# 3. Generaci√≥n de la Tabla de Producci√≥n Acumulada
print("\n" + "="*80)
print("‚≠ê TABLA DE PRODUCCI√ìN ACUMULADA (BBL) EN EL CONJUNTO DE PRUEBA")
print("="*80)
print(cumulative_production_df.round(2).to_markdown())


# 4. Generaci√≥n de la Gr√°fica de Producci√≥n Acumulada
plt.figure(figsize=(12, 6))

plt.plot(cumulative_production_df.index, cumulative_production_df['Producci√≥n Real'], 
         label='1. Producci√≥n Real Acumulada', color='blue', linewidth=3)
plt.plot(cumulative_production_df.index, cumulative_production_df['Pron√≥stico Arps Puro'], 
         label='2. Pron√≥stico Arps Puro', color='orange', linestyle=':', linewidth=2)
plt.plot(cumulative_production_df.index, cumulative_production_df['Pron√≥stico LSTM'], 
         label='3. H√≠brido LSTM', color='green', linestyle='--', linewidth=2)
plt.plot(cumulative_production_df.index, cumulative_production_df['Pron√≥stico Red Densa'], 
         label='4. H√≠brido Red Densa', color='darkcyan', linestyle='-.', linewidth=2)
plt.plot(cumulative_production_df.index, cumulative_production_df['Pron√≥stico CNN-LSTM'], 
         label='5. H√≠brido CNN-LSTM', color='red', linestyle='-', linewidth=1.5)

plt.title('Comparaci√≥n de la Producci√≥n Acumulada (Conjunto de Prueba)')
plt.xlabel('Fecha')
plt.ylabel('Petr√≥leo Acumulado (BBL)')
plt.legend(loc='upper left')
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


